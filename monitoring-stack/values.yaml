# Default values for monitoring-stack

# Global settings
global:
  namespace: monitoring

# Prometheus configuration
prometheus:
  enabled: true
  replicas: 1
  image:
    repository: prom/prometheus
    tag: v2.48.0
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "2000m"
  persistence:
    enabled: true
    storageClass: "local-path"
    size: 50Gi
  retention: 15d
  service:
    type: ClusterIP
    port: 9090
  scrapeInterval: 30s
  evaluationInterval: 30s

# Alertmanager configuration
alertmanager:
  enabled: true
  replicas: 1
  image:
    repository: prom/alertmanager
    tag: v0.26.0
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "256Mi"
      cpu: "200m"
  persistence:
    enabled: true
    storageClass: "local-path"
    size: 10Gi
  service:
    type: ClusterIP
    port: 9093
  config:
    # Default alertmanager configuration
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'slack'
    receivers:
      - name: 'slack'
        slack_configs:
          - api_url_file: '/etc/alertmanager/secrets/slack-webhook-url'
            channel: '#alerts'
            title: '{{ "{{" }} template "slack.default.title" . {{ "}}" }}'
            text: '{{ "{{" }} template "slack.default.text" . {{ "}}" }}'
            send_resolved: true
      - name: 'default'
        slack_configs:
          - api_url_file: '/etc/alertmanager/secrets/slack-webhook-url'
            channel: '#alerts'
    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'cluster', 'service']

# Grafana configuration
grafana:
  enabled: true
  replicas: 1
  image:
    repository: grafana/grafana
    tag: 10.2.2
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  persistence:
    enabled: true
    storageClass: "local-path"
    size: 10Gi
  service:
    type: LoadBalancer
    port: 3000
  adminUser: admin
  adminPassword: admin  # Change this!
  datasources:
    prometheus:
      enabled: true
      url: http://prometheus:9090
      isDefault: true
    loki:
      enabled: true
      url: http://loki-stack.observability.svc.cluster.local:3100

# Node Exporter configuration
nodeExporter:
  enabled: true
  image:
    repository: prom/node-exporter
    tag: v1.7.0
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "128Mi"
      cpu: "100m"
  service:
    port: 9100

# Kube State Metrics configuration
kubeStateMetrics:
  enabled: true
  image:
    repository: registry.k8s.io/kube-state-metrics/kube-state-metrics
    tag: v2.10.1
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "256Mi"
      cpu: "200m"
  service:
    port: 8080

# Alert rules
alertRules:
  enabled: true
  groups:
    - name: node-alerts
      rules:
        - alert: HighCPUUsage
          expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High CPU usage detected"
            description: "CPU usage is above 80% for {{ $labels.instance }}"
        - alert: HighMemoryUsage
          expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 80
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "High memory usage detected"
            description: "Memory usage is above 80% for {{ $labels.instance }}"
        - alert: DiskSpaceLow
          expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 20
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Disk space is low"
            description: "Disk space is below 20% for {{ $labels.instance }}"
    - name: pod-alerts
      rules:
        - alert: PodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Pod is crash looping"
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
        - alert: PodNotReady
          expr: kube_pod_status_phase{phase!="Running"} == 1
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Pod is not ready"
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready"

# ServiceMonitor for Prometheus Operator (optional)
serviceMonitor:
  enabled: false
  interval: 30s
